{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Adaptive and Reliable Classification\n",
    "\n",
    "This notebook provides a demonstration of the Adaptive and Reliable Classification (ARC) Python package through numerical experiments with simulated data.\n",
    "\n",
    "Accompanying paper:\n",
    " - \"Classification with Valid and Adaptive Coverage\", Y. Romano, M. Sesia, E. Cand√®s, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skgarden'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-a676e5831d1e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minsert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'..'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0marc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0marc\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0marc\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmethods\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mZ:\\Thesis\\code\\arc\\arc\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0marc\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmethods\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0marc\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mblack_boxes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0marc\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mothers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0marc\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcoverage\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mZ:\\Thesis\\code\\arc\\arc\\others.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mskgarden\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mRandomForestQuantileRegressor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstats\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmstats\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmquantiles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'skgarden'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import arc\n",
    "from arc import models\n",
    "from arc import methods\n",
    "from arc import black_boxes\n",
    "from arc import others\n",
    "from arc import coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)                                   # Make this notebook reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We generate data from a toy model with 10 explanatory variables and a qualitative label for each sample, which is designed to mimic \"heteroschedasticity\" in a classification setting.\n",
    "More precisely, the first variable controls the \"noise level\" in the label: small values of $X_0$ mean that all labels are more or less equally likely; large values of $X_0$ mean that one label is much more likely than the others (which one is determined by the other features).\n",
    "To clarify, we visualize below the distribution of the true label probabilities (for one value of the label) as a function of $X_0$, which here can take only two possible values for simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10                                                 # Number of features\n",
    "K = 10                                                 # Number of possible labels\n",
    "data_model = models.Model_Ex1(K,p)                     # Data generating model\n",
    "\n",
    "n = 500                                                # Number of data samples\n",
    "X = data_model.sample_X(n)                             # Generate the data features\n",
    "Y = data_model.sample_Y(X)                             # Generate the data labels conditional on the features\n",
    "\n",
    "n_test = 1000                                          # Number of test samples\n",
    "X_test = data_model.sample_X(n_test)                   # Generate independent test data\n",
    "Y_test = data_model.sample_Y(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating prediction sets\n",
    "\n",
    "We will evaluate prediction sets in terms of marginal coverage, estimated worst-slice conditional coverage, size, and size conditional on coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(S, X, y, conditional=True):\n",
    "    # Marginal coverage\n",
    "    marg_coverage = np.mean([y[i] in S[i] for i in range(len(y))])\n",
    "    if conditional:\n",
    "        # Estimated conditional coverage (worse-case slab)\n",
    "        wsc_coverage = coverage.wsc_unbiased(X, y, S, M=100)\n",
    "    else:\n",
    "        wsc_coverage = None\n",
    "    # Size and size conditional on coverage\n",
    "    size = np.mean([len(S[i]) for i in range(len(y))])\n",
    "    idx_cover = np.where([y[i] in S[i] for i in range(len(y))])[0]\n",
    "    size_cover = np.mean([len(S[i]) for i in idx_cover])\n",
    "    # Combine results\n",
    "    out = pd.DataFrame({'Coverage': [marg_coverage], 'Conditional coverage': [wsc_coverage],\n",
    "                        'Size': [size], 'Size cover': [size_cover]})\n",
    "    return out\n",
    "\n",
    "def evaluate_predictions_2(S, X, y, condition_on):\n",
    "    # Evaluate conditional coverage given a desired set of variables\n",
    "    cover = np.array([y[i] in S[i] for i in range(len(y))])\n",
    "    length = np.array([len(S[i]) for i in range(len(y))])\n",
    "    out = pd.DataFrame({'Cover': cover, 'Length': length})\n",
    "    for j in condition_on:\n",
    "        var_name = \"X{}\".format(j)\n",
    "        out[var_name] = X[:,j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical experiments\n",
    "\n",
    "The following code will sample independent train and test data sets and apply to them all requested methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_model, n_train, methods, black_boxes, condition_on,\n",
    "                   alpha=0.1, experiment=0, random_state=2020):\n",
    "    # Set random seed\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Total number of samples\n",
    "    n_test = 5000\n",
    "    n = n_train + n_test\n",
    "\n",
    "    # Generate data\n",
    "    X = data_model.sample_X(n)\n",
    "    y = data_model.sample_Y(X)\n",
    "    # Split data into train/test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=n_test, random_state=random_state)\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "    results_full = pd.DataFrame()\n",
    "    for box_name in black_boxes:\n",
    "        black_box = black_boxes[box_name]\n",
    "        for method_name in methods:\n",
    "            # Train classification method\n",
    "            method = methods[method_name](X_train, y_train, black_box, alpha, random_state=random_state)\n",
    "            # Apply classification method\n",
    "            S = method.predict(X_test)\n",
    "\n",
    "            # Evaluate results\n",
    "            res = evaluate_predictions(S, X_test, y_test)\n",
    "            # Add information about this experiment\n",
    "            res['Method'] = method_name\n",
    "            res['Black box'] = box_name\n",
    "            res['Experiment'] = experiment\n",
    "            res['Nominal'] = 1-alpha\n",
    "            res['n_train'] = n_train\n",
    "            res['n_test'] = n_test\n",
    "\n",
    "            # Evaluate results (conditional)\n",
    "            res_full = evaluate_predictions_2(S, X_test, y_test, condition_on)\n",
    "            # Add information about this experiment\n",
    "            res_full['Method'] = method_name\n",
    "            res_full['Black box'] = box_name\n",
    "            res_full['Experiment'] = experiment\n",
    "            res_full['Nominal'] = 1-alpha\n",
    "            res_full['n_train'] = n_train\n",
    "            res_full['n_test'] = n_test\n",
    "\n",
    "            # Add results to the list\n",
    "            results = results.append(res)\n",
    "            results_full = results_full.append(res_full)\n",
    "\n",
    "    return results, results_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the following calibration methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment/uncomment methods to be compared\n",
    "methods = {\n",
    "           'SC': arc.methods.SplitConformal, \n",
    "           'CV+': arc.methods.CVPlus, \n",
    "#           'JK+': arc.methods.JackknifePlus,\n",
    "           'HCC': arc.others.SplitConformalHomogeneous,\n",
    "           'CQC': arc.others.CQC\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "p = 10\n",
    "mod_xy = arc.models.Model_Ex1(K,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the performance of each calibration method in combination with the following black-box classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment/uncomment black-boxes to be compared\n",
    "black_boxes = {\n",
    "               'Oracle': arc.black_boxes.Oracle(mod_xy),\n",
    "               'SVC': arc.black_boxes.SVC(clip_proba_factor = 1e-5, random_state=2020),\n",
    "#              'RFC': arc.black_boxes.RFC(clip_proba_factor = 1e-5, \n",
    "#                                         n_estimators=1000, max_depth=5, max_features=None,\n",
    "#                                         random_state=2020)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run independent experiments with this setup, aiming to produce prediction sets with $1-\\alpha$ coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1                         # 1-desired marginal coverage level\n",
    "n = 1000                            # Number of training samples per experiment\n",
    "n_experiments = 30                  # Number of independent experiments\n",
    "\n",
    "condition_on = [0]                  # Variables to condition coverage on\n",
    "    \n",
    "# Run experiments\n",
    "results = pd.DataFrame()\n",
    "results_full = pd.DataFrame()\n",
    "for experiment in tqdm(range(n_experiments)):\n",
    "    \n",
    "    # Random state for this experiment\n",
    "    random_state = 2020 + experiment\n",
    "\n",
    "    res, res_full = run_experiment(mod_xy, n, methods, black_boxes, condition_on, \n",
    "                                   alpha=alpha, experiment=experiment, random_state=random_state)\n",
    "    results = results.append(res)\n",
    "    results_full = results_full.append(res_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y=\"Coverage\", x=\"Black box\", hue=\"Method\", data=results)\n",
    "#ax = sns.swarmplot(y=\"Coverage\", x=\"Black box\", hue=\"Method\", data=results, color=\".25\",dodge=True)\n",
    "ax.set(xlabel='Method', ylabel='Marginal coverage')\n",
    "ax.axhline(1-alpha, ls='--', color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y=\"Conditional coverage\", x=\"Black box\", hue=\"Method\", data=results)\n",
    "ax.set(xlabel='Method', ylabel='Conditional coverage')\n",
    "ax.axhline(1-alpha, ls='--', color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y=\"Size cover\", x=\"Black box\", hue=\"Method\", data=results)\n",
    "ax.set(xlabel='Method', ylabel='Conditional size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}